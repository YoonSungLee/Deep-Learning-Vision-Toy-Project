{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance Segmentation을 이해함에 있어서 그 기저가 되는 Object Detection과 Segmentation을 이해하는 것은 필수이다. 이번 Report는 Object Detection의 개념과 작동원리에 대해서 명확하게 이해하는 것이 목적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/bGpdSjp.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Detection을 이해하기 위해서는 그것의 기저인 Image Classification과 Localization을 이해해야한다. 맨 왼쪽 그림은 Image Classification으로 단순히 Image 내의 물체가 어떤 물체인지 분류해준다. 나아가 가운데 그림은 Image 내의 물체를 분류해주고 그 물체의 Bounding Box를 잡아준다. 이 때 지금까지 언급한 두 문제는 Image내의 하나의 물체만을 대상으로 한다. 만약 그 대상이 많아진다면 물체 각각에 대하여 분류해주고 Bounding Box를 잡아주어야 할 것이다. 이것이 바로 Object Detection이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/79QEXs2.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 언급한 문제 중 'Classification with Localization' 문제를 좀 더 살펴보자. 모델은 위와 같이 구성된다. 마지막 출력층을 보면 기존 Classification 문제를 해결하기 위한 softmax 분류 layer 뿐만 아니라 물체의 Bounding Box를 출력하는 층이 포함된다. 해당 층은 총 4개의 결과를 출력하는데, Bounding Box의 중심좌표에 해당하는 bx, by, Bounding Box의 높이와 너비에 해당하는 bh, bw가 그것이다. 특히 분류를 함에 있어서 Bounding Box안에 물체가 없을 경우가 있으므로 background에 해당하는 클래스를 하나 추가해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/CTwRVx9.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target label을 만드는 방법은 위와 같다. y 벡터는 물체의 존재 여부(물체가 있는지 나타내는 확률)를 표현하는 pc, Bounding Box의 정보를 표현하는 bx, by, bh, bw, 그리고 클래스 별 존재확률인 c1, c2, c3, ... 으로 구성된다. 특히 pc의 경우 물체가 있다면 1, 없다면 0의 값을 갖는데, 만약 물체가 없다면 나머지 원소들의 값이 무의믜하므로 신경쓰지 않는다. 따라서 Loss Function의 구성을 생각해보자면 다음과 같다. 먼저 물체가 존재하는 경우(y=1)는 y_hat과 y벡터의 L2 Loss를 통해 그 차이를 계산할 수 있다. 물체가 존재하지 않는 경우(y=0)는 pc의 값만 유의미하기 때문에 y_hat과 y 벡터의 pc에 해당하는 원소만 제곱 오차를 사용하여 그 차이를 계산한다. 물론 이는 가장 간편한 방법이고, 설계에 따라서 pc부분을 로지스틱 회귀 손실을 사용할 수도 있고, c1, c2, c3, ...부분을 로그 우도 손실을 사용할 수  도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/buozZbl.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 살펴볼 내용은 Landmark Detection(특징점 검출)이다. 흔히 Face Recognition 문제나 Pose Estimation 문제가 이에 해당한다. 이는 Object Localization과는 달리 얼굴 인식에 중요한 특징점 또는 자세 추정에 중요한 특징점 등 문제를 해결하기에 중요하다고 생각하는 특징점들의 좌표를 예측하는 문제이다. 따라서 y 벡터는 물체의 존재 여부(물체가 있는지 나타내는 확률)를 표현하는 pc, 특징점들의 좌표를 표현하는 l1x, l1y, l2x, l2y, ...로 구성되어있다. 예를 들어 위의 가운데 이미지는 Face Recognition 문제에 해당하는데, 얼굴의 존재여부를 표현하는 원소, 그리고 얼굴인식에 중요하다고 생각하는 64개 특징점의 좌표를 표현하는 원소로 이루어져 총 129개의 원소를 가지는 y 벡터가 필요할 것이다. 특히 중요한 점은 특징점은 다른 이미지에 대해서도 항상 동일해야 한다는 점이다. 예를 들어 특징점 1은 항상 왼쪽 눈의 눈꼬리가 되어야 하고, 특징점 2는 항상 오른쪽 눈의 눈꼬리가 되어야 한다. 이렇듯 레이블 순서는 다른 이미지에 대해서도 항상 동일하게 구성되어 있어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deeplearning.ai\n",
    "* https://www.deeplearning.ai/\n",
    "* https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
